<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" />
<title>Basic Object Detection</title>
<style>
  /* Reset and base */
  * {
    box-sizing: border-box;
  }
  body {
    margin: 0;
    background: linear-gradient(135deg, #667eea, #764ba2);
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    color: #f0f0f0;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: flex-start;
    min-height: 100vh;
    max-height: 600px;
    max-width: 350px;
    margin: auto;
    padding: 0.5rem;
  }

  h1 {
    margin: 0.5rem 0 1rem;
    font-weight: 700;
    font-size: 1.6rem;
    text-align: center;
    text-shadow: 1px 1px 5px rgba(0,0,0,0.5);
  }

  #video-container {
    position: relative;
    width: 100%;
    max-width: 350px;
    aspect-ratio: 4 / 3;
    background: #222;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 0 25px #3a3f8f;
  }

  video {
    width: 100%;
    height: auto;
    display: block;
    filter: brightness(1.1);
  }

  canvas {
    position: absolute;
    top: 0;
    left: 0;
    z-index: 10;
    width: 100%;
    height: 100%;
    pointer-events: none;
  }

  #controls {
    margin-top: 0.5rem;
    width: 100%;
    display: flex;
    justify-content: space-around;
  }

  button {
    background: #4c48cc;
    border: none;
    border-radius: 8px;
    padding: 0.5rem 1.2rem;
    font-size: 1rem;
    color: #eee;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.3s ease;
    box-shadow: 0 0 12px #4c48cc;
  }
  button:hover, button:focus {
    background: #6e6acd;
    outline: none;
  }
  button:disabled {
    background: #888;
    cursor: default;
    box-shadow: none;
  }

  #status {
    margin-top: 1rem;
    font-size: 1rem;
    font-weight: 600;
    text-align: center;
    min-height: 1.2rem;
    user-select: none;
    text-shadow: 1px 1px 6px rgba(0,0,0,0.7);
  }

  /* Responsive text and container */
  @media (max-width: 400px) {
    body {
      max-width: 100vw;
      padding: 0.25rem;
    }
    h1 {
      font-size: 1.3rem;
    }
    button {
      font-size: 0.9rem;
      padding: 0.4rem 1rem;
    }
  }
</style>
</head>
<body>
  <h1>Basic Object Detection</h1>
  <div id="video-container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="controls">
    <button id="startBtn">Start Detection</button>
    <button id="stopBtn" disabled>Stop Detection</button>
  </div>
  <div id="status">Click "Start Detection" to begin</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script>
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const statusText = document.getElementById('status');

  let model = null;
  let isDetecting = false;
  let videoStream = null;
  let detectInterval = null;

  async function setupCamera() {
    statusText.textContent = 'Requesting camera access...';
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      statusText.textContent = 'Camera API not supported in this browser.';
      throw new Error('Camera API not supported');
    }

    videoStream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'environment', width: 640, height: 480 },
      audio: false
    });
    video.srcObject = videoStream;

    return new Promise((resolve) => {
      video.onloadedmetadata = () => {
        resolve(video);
      };
    });
  }

  async function loadModel() {
    statusText.textContent = 'Loading object detection model...';
    model = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
    statusText.textContent = 'Model loaded. Ready to start detection.';
  }

  function clearCanvas() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
  }

  function drawBoundingBox(prediction) {
    const [x, y, width, height] = prediction.bbox;
    ctx.strokeStyle = '#00ffcc';
    ctx.lineWidth = 3;
    ctx.fillStyle = '#00ffcc';
    ctx.font = '18px Segoe UI, Tahoma, Geneva, Verdana, sans-serif';
    ctx.textBaseline = 'top';
    ctx.strokeRect(x, y, width, height);
    const text = `${prediction.class} (${(prediction.score * 100).toFixed(1)}%)`;
    const textWidth = ctx.measureText(text).width;
    const textHeight = 22;
    ctx.fillRect(x, y, textWidth + 8, textHeight);
    ctx.fillStyle = '#000';
    ctx.fillText(text, x + 4, y + 2);
  }

  function resizeCanvas() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
  }

  async function detectFrame() {
    if (!isDetecting) return;
    if (!model) {
      statusText.textContent = 'Model not loaded.';
      return;
    }
    if (video.readyState !== 4) {
      // Video not ready
      requestAnimationFrame(detectFrame);
      return;
    }

    resizeCanvas();
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    const predictions = await model.detect(video);

    // Filter predictions for objects of interest only
    const objectsOfInterest = ['book', 'cell phone', 'cup', 'bottle', 'remote', 'laptop', 'keyboard', 'mouse', 'pen', 'scissors', 'toothbrush', 'tv', 'clock', 'vase', 'bowl', 'fork', 'spoon', 'knife', 'handbag', 'backpack', 'tie', 'umbrella', 'frisbee', 'sports ball', 'baseball bat', 'baseball glove', 'skis', 'snowboard', 'kite', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'glasses', 'book']; 
    // Note: 'pen' and 'glasses' may not be accurately detected by COCO-SSD, kept for demo.

    const filteredPredictions = predictions.filter(pred => objectsOfInterest.includes(pred.class));

    if (filteredPredictions.length > 0) {
      statusText.textContent = `Detected: ${filteredPredictions.map(p => p.class).join(', ')}`;
    } else {
      statusText.textContent = 'No familiar objects detected.';
    }

    filteredPredictions.forEach(prediction => {
      if (prediction.score > 0.4) {
        drawBoundingBox(prediction);
      }
    });

    requestAnimationFrame(detectFrame);
  }

  async function startDetection() {
    startBtn.disabled = true;
    stopBtn.disabled = false;
    try {
      if (!videoStream) {
        await setupCamera();
      }
      await loadModel();
      isDetecting = true;
      detectFrame();
      statusText.textContent = 'Detecting objects...';
    } catch (error) {
      console.error(error);
      statusText.textContent = 'Error accessing camera or loading model.';
      startBtn.disabled = false;
      stopBtn.disabled = true;
    }
  }

  function stopDetection() {
    isDetecting = false;
    startBtn.disabled = false;
    stopBtn.disabled = true;
    statusText.textContent = 'Detection stopped.';
    clearCanvas();
    if (videoStream) {
      videoStream.getTracks().forEach(track => track.stop());
      video.srcObject = null;
      videoStream = null;
    }
  }

  startBtn.addEventListener('click', startDetection);
  stopBtn.addEventListener('click', stopDetection);

  // On page load, just set status
  statusText.textContent = 'Click "Start Detection" to begin detecting objects.';
</script>
</body>
</html>

